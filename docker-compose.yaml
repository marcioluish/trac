version: "3.8"

services:
  trac_backend:
    container_name: trac_backend
    image: trac_backend
    build:
      context: ./app
      dockerfile: Dockerfile
    volumes:
      # named volume
      - logs:/app/logs
      # bind volume
      - ./app:/app
      # anonymous volume
      - /app/node_modules
    env_file:
      - ./env/backend.env
    depends_on:
      - trac_db
    # TODO discard port 9229 used for debugging
    ports:
      - 8000:8000
      - 9229:9229
    networks:
      - trac
  
  trac_db:
    container_name: trac_db
    image: "mongo:5.0.0"
    volumes:
      - data:/data/db
    env_file:
      - ./env/mongo.env
    networks:
      - trac

  zookeeper:
    restart: always
    image: confluentinc/cp-zookeeper:6.1.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - trac

  broker:
    restart: always
    image: confluentinc/cp-kafka:6.1.1
    hostname: broker
    container_name: broker
    ports:
      - 29092:29092
      - 9092:9092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
    networks:
      - trac

  status_topic:
    image: confluentinc/cp-kafka:6.1.1
    command: bash -c "cub kafka-ready -z zookeeper:2181 1 30 && kafka-topics --zookeeper zookeeper:2181 --create --topic trac_status --if-not-exists --partitions 1 --replication-factor 1"
    depends_on:
      - zookeeper
    networks:
      - trac

  health_level_topic:
    image: confluentinc/cp-kafka:6.1.1
    command: bash -c "cub kafka-ready -z zookeeper:2181 1 30 && kafka-topics --zookeeper zookeeper:2181 --create --topic health_level --if-not-exists --partitions 1 --replication-factor 1"
    depends_on:
      - zookeeper
    networks:
      - trac

  kafka-connect:
    restart: always
    image: confluentinc/cp-kafka-connect:5.1.2
    hostname: kafka-connect
    container_name: kafka-connect
    volumes:
      - ./kafka_scripts:/srv/scripts
    depends_on:
      - zookeeper
      - broker
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/confluent-hub-components"
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.2.2.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR,com.mongodb.kafka=DEBUG"
    command:
      - bash 
      - -c 
      - |
        # 
        echo "Installing Connector"
        confluent-hub install --no-prompt mongodb/kafka-connect-mongodb:latest

        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &

        #
        echo "Waiting for Connectors build up"
        while [ $$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) -eq 000 ] ; do 
          echo -e $$(date) "Kafka Connect listener HTTP state: " $$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) " (waiting for 200)"
          sleep 5 
        done
        nc -vz localhost 8083
        echo -e "Creating connection between local database and kafka"
        chmod +x /srv/scripts/connect-cloud.sh
        /srv/scripts/connect-cloud.sh
        #
        sleep infinity
    networks:
      - trac

volumes:
  logs:
  data:

networks:
  trac: